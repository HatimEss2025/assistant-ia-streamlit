import os
import json
import pandas as pd
import streamlit as st

from bs4 import BeautifulSoup
from PyPDF2 import PdfReader
import docx2txt
from openpyxl import load_workbook
from dotenv import load_dotenv

from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.docstore.document import Document

# -------------------------
# Initialisation et config
# -------------------------
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    st.error("‚ùå Cl√© API OpenAI manquante. Ajoutez-la dans Streamlit Cloud (Settings > Secrets)")
    st.stop()

# -------------------------
# Lecture de fichiers
# -------------------------
dataframes_excels = {}
MAX_CHARS = 50000

def lire_contenu_fichier(uploaded_file):
    try:
        nom = uploaded_file.name
        if nom.endswith(".csv"):
            df = pd.read_csv(uploaded_file)
            dataframes_excels[nom] = df
            contenu = df.to_string()
        elif nom.endswith(".xlsx"):
            df = pd.read_excel(uploaded_file, engine="openpyxl")
            dataframes_excels[nom] = df
            contenu = df.to_string()
        elif nom.endswith(".txt"):
            contenu = uploaded_file.read().decode("utf-8")
        elif nom.endswith(".pdf"):
            reader = PdfReader(uploaded_file)
            contenu = "\n".join([p.extract_text() for p in reader.pages if p.extract_text()])
        elif nom.endswith(".docx"):
            contenu = docx2txt.process(uploaded_file)
        elif nom.endswith(".json"):
            data = json.load(uploaded_file)
            contenu = json.dumps(data, indent=2)
        elif nom.endswith((".md", ".html", ".htm")):
            soup = BeautifulSoup(uploaded_file.read(), "html.parser")
            contenu = soup.get_text()
        else:
            return None

        if len(contenu) > MAX_CHARS:
            contenu = contenu[:MAX_CHARS]
        return contenu
    except Exception as e:
        return f"Erreur de lecture : {e}"

# -------------------------
# Analyse IA
# -------------------------
def creer_qa_conversation(documents):
    splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)
    docs = splitter.split_documents(documents[:50])

    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    vectordb = FAISS.from_documents(docs, embeddings)
    retriever = vectordb.as_retriever()

    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True,
        output_key="answer"
    )

    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=ChatOpenAI(model_name="gpt-3.5-turbo", openai_api_key=OPENAI_API_KEY),
        retriever=retriever,
        memory=memory,
        return_source_documents=True,
        output_key="answer"
    )
    return qa_chain

# -------------------------
# Interface Streamlit
# -------------------------
st.set_page_config(page_title="Assistant IA", page_icon="üß†")
st.title(" üß† Assistant IA ‚Äì Analyse de fichiers Excel/CSV")

uploaded_files = st.file_uploader("üìÅ Importez vos fichiers", type=["csv", "xlsx", "txt", "pdf", "docx", "json", "html"], accept_multiple_files=True)

if "qa_chain" not in st.session_state:
    st.session_state.qa_chain = None
if "historique" not in st.session_state:
    st.session_state.historique = []

if uploaded_files:
    with st.spinner("üìÑ Lecture et indexation des documents..."):
        documents = []
        for f in uploaded_files:
            contenu = lire_contenu_fichier(f)
            if contenu:
                documents.append(Document(page_content=f"Nom du fichier : {f.name}\n\n{contenu}", metadata={"source": f.name}))
        if documents:
            st.session_state.qa_chain = creer_qa_conversation(documents)
            st.success("‚úÖ Fichiers trait√©s et index√©s avec succ√®s")
        else:
            st.error("‚ùå Aucun contenu valide n'a √©t√© trouv√©.")

if st.session_state.qa_chain:
    with st.form("formulaire_question", clear_on_submit=True):
        question = st.text_input("üí¨ Posez votre question sur les fichiers :")
        submit = st.form_submit_button("Envoyer")

    if submit and question:
        with st.spinner("ü§ñ Traitement par l'IA..."):
            import io
            from langchain.chains import LLMChain
            from langchain.prompts import PromptTemplate

            extrait_csv = ""
            for df in dataframes_excels.values():
                buffer = io.StringIO()
                df.head(10).to_csv(buffer, index=False)
                extrait_csv += buffer.getvalue() + "\n"

            prompt = PromptTemplate.from_template(
                "Voici un extrait des fichiers Excel/CSV charg√©s :\n{data}\n\nQuestion : {question}"
            )

            chain = LLMChain(
                llm=ChatOpenAI(model_name="gpt-3.5-turbo", openai_api_key=OPENAI_API_KEY),
                prompt=prompt
            )
            reponse = chain.run(data=extrait_csv, question=question)
            st.session_state.historique.append((question, reponse))

if st.session_state.historique:
    st.markdown("### üìú Historique")
    for q, r in reversed(st.session_state.historique):
        st.markdown(f"**üó£Ô∏è Vous :** {q}")
        st.markdown(f"**ü§ñ IA :** {r}")
        st.markdown("---")
